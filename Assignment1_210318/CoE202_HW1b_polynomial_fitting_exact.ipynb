{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoE202_HW1b_polynomial_fitting_exact.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2vJ63lCf3Xu"
      },
      "source": [
        "# [CoE202] **[Homework1b]** Polynomial regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0X8_93xXjDM"
      },
      "source": [
        "In this section, you are going to implement polynomial regression algorithms using closed form solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSPn8Tj2XWfI"
      },
      "source": [
        "### 0. Importing packages\r\n",
        "\r\n",
        "For this assignment we need Numpy and Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgDkjzWqw2HR"
      },
      "source": [
        "# this is just an annotation\n",
        "import numpy as np # this is for importing numpy library (and we will use abbreviation np for that)\n",
        "import matplotlib.pyplot as plt # this is for importing matplotlib.pyplot (library for graph plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9FyuYPqXn1e"
      },
      "source": [
        "### 1. Introduction \r\n",
        "Given data points (x, y), we want to find non-linear estimator that fits well on the data. We are going to consider the only case when x and y are single dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIXwKvH1xCAd"
      },
      "source": [
        "# data points\n",
        "X = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
        "y = np.array([0.0, 0.8, 2.9, 5.1, 8.8, 15.1])\n",
        "\n",
        "# plot data\n",
        "plt.plot(X, y, 'bo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fivzBgkcsupZ"
      },
      "source": [
        "### 2. Polynomial regression with closed solution\n",
        "\n",
        "One class of functions that is covered by linear regression is the family of polynomials because we can write a polynomial of degree $K$ as\n",
        "$$\n",
        "\\sum_{k=0}^K \\theta_k x^k = \\boldsymbol \\phi(x)^T\\boldsymbol\\theta\\,,\\quad\n",
        "\\boldsymbol\\phi(x)= \n",
        "\\begin{bmatrix}\n",
        "x^0\\\\\n",
        "x^1\\\\\n",
        "\\vdots\\\\\n",
        "x^K\n",
        "\\end{bmatrix}\\in\\mathbb{R}^{K+1}\\,.\n",
        "$$\n",
        "Here, $\\boldsymbol\\phi(x)$ is a nonlinear feature transformation of the inputs $x\\in\\mathbb{R}$.\n",
        "\n",
        "Similar to the earlier case we can define a matrix that collects all the feature transformations of the training inputs:\n",
        "$$\n",
        "\\boldsymbol\\Phi = \\begin{bmatrix}\n",
        "\\boldsymbol\\phi(x_1) & \\boldsymbol\\phi(x_2) & \\cdots & \\boldsymbol\\phi(x_n)\n",
        "\\end{bmatrix}^T \\in\\mathbb{R}^{N\\times K+1}\n",
        "$$\n",
        "For the above data, $K=2$ (quadratic estimator) seems to be good approximation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP3TzzIGLyKm"
      },
      "source": [
        "def poly_features(X, K):\n",
        "    \"\"\"Compute the feature matrix Phi\n",
        "\n",
        "    Arguments:\n",
        "      X: input data of size N vector\n",
        "      K: degree of the polynomial\n",
        "    \n",
        "    Returns:\n",
        "      Phi: feature matrix of size N x (K + 1)\n",
        "    \"\"\"\n",
        "    # [Problem 1] returns feature matrix Phi from input and degree of the polynomial\n",
        "    # HINT: np.vander to generate a Vandermonde matrix.\n",
        "    # Fill out here       Phi = _________\n",
        "\n",
        "    return Phi\n",
        "\n",
        "def vectorize_y(y):\n",
        "    y_vec = y.reshape(-1, 1) \n",
        "    return y_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ4SMc28L1AQ"
      },
      "source": [
        "K = 2\n",
        "Phi = poly_features(X, K)\n",
        "y_vec = vectorize_y(y)\n",
        "\n",
        "print(Phi)\n",
        "print(y_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQY1l1KgNsB1"
      },
      "source": [
        "  With this feature matrix we get the theta as\n",
        "  $$\n",
        "  \\boldsymbol \\theta = (\\boldsymbol\\Phi^T\\boldsymbol\\Phi)^{-1}\\boldsymbol\\Phi^T\\boldsymbol y\n",
        "  $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pDXDNHCutLK"
      },
      "source": [
        "# memo: np.dot is somewhat confusing. Let's use matmul or @ \n",
        "def np_polynomial_regression(Phi, y):\n",
        "    \"\"\"Compute the coefficients by closed form polynomial fitting.\n",
        "\n",
        "    Arguments:\n",
        "      Phi: feature matrix of size N x (K + 1)\n",
        "      y: training targets of size N x 1\n",
        "    \n",
        "    Returns:\n",
        "      theta_ml: coefficients of the polynomial function.\n",
        "    \"\"\"\n",
        "    # [Problem 2] Make function that returns theta from Phi and y.\n",
        "    # Fill out here       theta = _________\n",
        "    \n",
        "    return theta_ml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnGLCb-aY0Vu"
      },
      "source": [
        "### 3. Testing algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyFGCAu3NDod"
      },
      "source": [
        "# get coefficients \n",
        "theta_ml = np_polynomial_regression(Phi, y_vec)\n",
        "print(theta_ml)\n",
        "\n",
        "# test inputs\n",
        "Xtest = np.linspace(-1,6,100)\n",
        "\n",
        "# feature matrix for test inputs\n",
        "Phi_test = poly_features(Xtest, K)\n",
        "\n",
        "y_pred = Phi_test @ theta_ml # predicted y-values\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(X, y, '+')\n",
        "plt.plot(Xtest, y_pred)\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.ylabel(\"$y$\");"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}